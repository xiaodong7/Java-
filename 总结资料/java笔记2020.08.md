## java笔记

[toc]







1. **锁的分类**

   **乐观锁与悲观锁**

   1.乐观锁，每次拿数据的时候认为别人都不会修改，在更新的时候再判断在此期间有没有更新数据，可以使用版本号等机制，适合读取多场景，提高性能。

   2.悲观锁，每次拿数据都认为别人会修改，都会上锁，可以使用synchronized、独占锁Lock、读写锁等机制，适合写多的场景，保证写入操作正确。

   **自旋锁与适应性自旋锁**

   - 自旋锁：指当一个线程在获取锁的时候，如果锁已经被其他线程获取，那么该线程将循环等待，然后不断判断锁是否能获取成功，直到获取到锁才退出循环。
   优点：线程不进行上下文切换，减少了上下文切换的时间。
      存在的问题：如果线程持有锁的时间较长，其他线程进入循环，消耗cpu。
- 自适应自旋锁：指的是自旋的时间不固定，由前一个在同一个锁上自旋的时间和锁拥有者的状态来决定。如果在同一个对象上，刚刚通过自旋成功获取过锁，且持有锁的线程正在运行中，那么虚拟机就会认为这次自旋很有可能再次成功。反之自旋操作很少成功获取锁，那么后面获取这个锁可能直接省略掉自旋的过程，直接阻塞线程。
  

**自旋锁**

      由于自旋锁使用者一般保持锁时间非常短，因此选择自旋而不是睡眠是非常必要的，自旋锁的效率远高于互斥锁。 
      如何旋转呢？何为自旋锁，就是如果发现锁定了，不是睡眠等待，而是采用让当前线程不停地的在循环体内执行（死循环）实现的，当循环的条件被其他线程改变时才能进入临界区。

- 自旋锁与互斥锁区别 
      互斥锁：线程会从sleep（加锁）——>running（解锁），过程中有上下文的切换，cpu的抢占，信号的发送等开销。 
   自旋锁：线程一直是running(加锁——>解锁)，死循环检测锁的标志位，机制不复杂。
  

**公平锁与非公平锁**

   1. 公平锁是指多个线程按照申请锁的顺序直接进入队列排队，队列中的第一个线程才能获取锁。
2. 非公平锁是指线程先尝试获取锁，获取不到进入队列中排队，如果能获取到，则无需阻塞直接获取锁。
   
      如果在绝对时间上，先对锁进行获取的请求一定先被满足，那么这个锁是公平的，反之，是不公平的。公平的获取锁，也就是等待时间最长的线程最优先获取锁，也可以说锁获取是顺序的。ReentrantLock类提供了一个构造函数public ReentrantLock(boolean fair) {}，能够控制锁是否是公平的。

- 公平锁： 
      公平和非公平锁的队列都基于锁内部维护的一个双向链表，表结点Node的值就是每一个请求当前锁的线程。公平锁则在于每次都是依次从队首取值。
- 非公平锁： 
      在等待锁的过程中， 如果有任意新的线程妄图获取锁，都是有很大的几率直接获取到锁的。
- 白话文:就是公平锁是先到先得,按序进行. 非公平锁就是不排队直接拿,失败再说。公平性锁保证了锁的获取按照FIFO原则，而代价是进行大量的线程切换。非公平性锁虽然可能造成线程“饥饿”，但极少的线程切换，保证了其更大的吞吐量。
  
   **重入锁与非重入锁**

   重入锁：同一个线程在外层方法获取锁的时候，在进入内层方法会自动获取锁，前提是锁对象是相同的。

   **共享锁与排他锁**

   1. 共享锁是指一个锁可以被多个线程锁持有。
2. 排它锁或者叫独享锁或者互斥锁 指锁一次只能被一个线程所持有。
   

**读写锁**

   1. 读锁是共享的，写锁是独占的。
   2. 读读之间不会互斥，读写互斥，写写互斥，读写锁提高了读的性能。

   **死锁**

   **死锁的定义**

   多线程以及多进程改善了系统资源的利用率并提高了系统 的处理能力。然而，并发执行也带来了新的问题——死锁。
 所谓死锁是指多个线程因竞争资源而造成的一种僵局（互相等待），若无外力作用，这些进程都将无法向前推进。

**死锁产生的原因**

可归结为如下两点：

a. 竞争资源

   系统中的资源可以分为两类：

   - 可剥夺资源，是指某进程在获得这类资源后，该资源可以再被其他进程或系统剥夺，CPU和主存均属于可剥夺性资源（例如：系统中只有一台打印机，可供进程P1使用，假定P1已占用了打印机，若P2继续要求打印机打印将阻塞）；
- 不可剥夺资源，当系统把这类资源分配给某进程后，再不能强行收回，只能在进程用完后自行释放，如磁带机、打印机等。
  

b. 进程间推进顺序非法

   - 若P1保持了资源R1,P2保持了资源R2，系统处于不安全状态，因为这两个进程再向前推进，便可能发生死锁
- 例如，当P1运行到P1：Request（R2）时，将因R2已被P2占用而阻塞；当P2运行到P2：Request（R1）时，也将因R1已被P1占用而阻塞，于是发生进程死锁。
  

**死锁产生的4个必要条件**

产生死锁的必要条件：

1. 互斥条件：进程要求对所分配的资源进行排它性控制，即在一段时间内某资源仅为一进程所占用。
   2. 请求和保持条件：当进程因请求资源而阻塞时，对已获得的资源保持不放。
   3. 不剥夺条件：进程已获得的资源在未使用完之前，不能剥夺，只能在使用完时由自己释放。
4. 环路等待条件：在发生死锁时，必然存在一个进程–资源的环形链。
   

   

**死锁的处理方法**

**预防**

1. 破坏”请求与保持"条件：第一种方法静态分配即每个进程在开始执行时就申请他所需要的全部资源。第二种是动态分配即每个进程在申请所需要的资源时他本身不占用系统资源。
   
   2. 破坏“不可剥夺”条件：一个进程不能获得所需要的全部资源时便处于等待状态，等待期间他占有的资源将被隐式的释放重新加入到系统的资源列表中，可以被其他的进程使用，而等待的进程只有重新获得自己原有的资源以及新申请的资源才可以重新启动，执行。
3. 破坏“循环等待”条件：采用资源有序分配其基本思想是将系统中的所有资源顺序编号，将紧缺的，稀少的采用较大的编号，在申请资源时必须按照编号的顺序进行，一个进程只有获得较小编号的进程才能申请较大编号的进程。
   

   
   **避免**

   - 系统处于安全状态（存在能让所有进程执行完的序列），可避免死锁
- 系统处于不安全状态，可能进入死锁状态（银行家算法）
  

  
   **检测**

   资源分配图不可完全简化，则是死锁状态

   

   **解除**

   处理抢占资源 / 终止死锁进程



- 什么是CAS 
   CAS：Compare and Swap，即比较再交换。 
   jdk5增加了并发包java.util.concurrent.*,其下面的类使用CAS算法实现了区别于synchronouse同步锁的一种乐观锁。JDK 5之前Java语言是靠synchronized关键字保证同步的，这是一种独占锁，也是是悲观锁。
- CAS算法理解 
   （1）与锁相比，使用比较交换（下文简称CAS）会使程序看起来更加复杂一些。但由于其非阻塞性，它对死锁问题天生免疫，并且，线程间的相互影响也远远比基于锁的方式要小。更为重要的是，使用无锁的方式完全没有锁竞争带来的系统开销，也没有线程间频繁调度带来的开销，因此，它要比基于锁的方式拥有更优越的性 
   （2）无锁的好处： 
   第一，在高并发的情况下，它比有锁的程序拥有更好的性能； 
   第二，它天生就是死锁免疫的。 
   就凭借这两个优势，就值得我们冒险尝试使用无锁的并发。 
   （3）CAS算法的过程是这样：它包含三个参数CAS(V,E,N): V表示要更新的变量，E表示预期值，N表示新值。仅当V值等于E值时，才会将V的值设为N，如果V值和E值不同，则说明已经有其他线程做了更新，则当前线程什么都不做。最后，CAS返回当前V的真实值。 
   （4）CAS操作是抱着乐观的态度进行的，它总是认为自己可以成功完成操作。当多个线程同时使用CAS操作一个变量时，只有一个会胜出，并成功更新，其余均会失败。失败的线程不会被挂起，仅是被告知失败，并且允许再次尝试，当然也允许失败的线程放弃操作。基于这样的原理，CAS操作即使没有锁，也可以发现其他线程对当前线程的干扰，并进行恰当的处理。 
   （5）简单地说，CAS需要你额外给出一个期望值，也就是你认为这个变量现在应该是什么样子的。如果变量不是你想象的那样，那说明它已经被别人修改过了。你就重新读取，再次尝试修改就好了。 
   （6）在硬件层面，大部分的现代处理器都已经支持原子化的CAS指令。在JDK 5.0以后，虚拟机便可以使用这个指令来实现并发操作和并发数据结构，并且，这种操作在虚拟机中可以说是无处不在。
- CAS（乐观锁算法）的基本假设前提 
   CAS比较与交换的伪代码可以表示为： 
   do{ 
     备份旧数据； 
     基于旧数据构造新数据； 
   }while(!CAS( 内存地址，备份的旧数据，新数据 )) 

![img](https://img-blog.csdn.net/20180618150708900?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3pwY2FuZHpoag==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)



2. 应用层——消息(message) 

​        传输层——数据段(segment) 

​        网络层——分组、数据包（packet,datagram） 

​        链路层——帧（frame） 

​        物理层——P-PDU（bit）



3. **使用UDP协议的应用层协议：DNS，TFTP，RIP，BOOTP，DHCP，SNMP，NFS**

   

     **使用TCP协议的应用层协议：SMTP，TELNET，HTTP，FTP**

​           RIP : UDP ; OSPF : IP; BGP : TCP

4. 二叉链表：  左孩子右兄弟 

二叉树中连接节点和节点的线就是度，有n个节点，就有n-1个度，根节点头上没有线，因此有以下公式：（N为二叉树的总度数）

  N+1=n0+n1+n2； 

  N=2*n2+1*n1+0*n0;

  求解即可得到：n2=n0-1,即度为2的节点数目等于度为0的节点数目-1



5. 三叉树

     节点总数-1=分支数 

     n1+n2+n3+n0 -1=分支数 

     又因为 分支数=各个节点的度数和 

     所以 

     n1+n2+n3+n0=n1*1+n2*2+n3*3 

     2+2+2+n0 -1 = 2+4+6 

     n0=7

### **多线程总结**

6. **形成死锁的四个必要条件是什么**

   （1）互斥条件：线程(进程)对于所分配到的资源具有排它性，即一个资源只能被一个线程(进程)占用，直到被该线程(进程)释放

   （2）请求与保持条件：一个线程(进程)因请求被占用资源而发生阻塞时，对已获得的资源保持不放。

   （3）不剥夺条件：线程(进程)已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。

   （4）循环等待条件：当发生死锁时，所等待的线程(进程)必定会形成一个环路（类似于死循环），造成永久阻塞


**如何避免线程死锁**

我们只要破坏产生死锁的四个条件中的其中一个就可以了。

**破坏互斥条件**

这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。

**破坏请求与保持条件**

一次性申请所有的资源。

**破坏不剥夺条件**

占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。

**破坏循环等待条件**

靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。



7. **常见的五中线程池****

【1】**Executors.newFixedThreadPool(n)：**创建一个定长的线程池，可控制线程最大并发数，超出的线程会在队列中等待。创建的线程池 corePoolSize 和 maximumPoolSize 值是相等的，使用的是 LinkedBlockingQueue 阻塞队列。执行长期的任务，性能好很多。底层实现如下：

public static ExecutorService newFixedThreadPool(int nThreads) {

```java

public static ExecutorService newFixedThreadPool(int nThreads) {

	return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS,

                                        new LinkedBlockingQueue<Runnable>());

}
```

【2】**Executors.newSingleThreadExecutor()：**创建一个单线程的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序执行。将 corePoolSize 和 maximumPoolSize 都设置为1，使用的是 LinkedBlockingQueue 阻塞队列。适合一个任务一个任务执行的场景。底层实现如下：

```jade

public static ExecutorService newSingleThreadExecutor() {

	return new FinalizableDelegatedExecutorService

		(new ThreadPoolExecutor(1, 1,0L, TimeUnit.MILLISECONDS,

		    new LinkedBlockingQueue<Runnable>()));

}
```

【3】**Executors.newCachedThreadPool()：**创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收线程，则新建线程。将 corePoolSize 设置为0，maximumPoolSize 设置为Integer.MAX_VALUE ，使用的阻塞队列是SynchronousQueue，也就是说来了任务就创建线程运行，当线程空闲超过60秒，就销毁线程。适合执行很多短期异步的小程序或者负载较轻的服务器。

```java
public static ExecutorService newCachedThreadPool() {

	return new ThreadPoolExecutor(0, Integer.MAX_VALUE,60L, TimeUnit.SECONDS,

				        new SynchronousQueue<Runnable>());

}
```

【4】**Executors.newScheduledThreadPool(n)：**了解
【5】**Executors.newWorkStealingPool()：**了解

> 阿里巴巴开发手册：①、线程资源必须通过线程池提供，不允许在应用中自行显示创建。因为使用线程池能够减少在创建和销毁线程上所消耗的时间以及系统开销，解决资源不足问题。如果不适用线程池，有可能造成系统创建大量同类线程而导致消耗完内存或“过度切换”的问题。②、线程池不允许使用 Executors 去创建，而是通过 ThreadPoolExecutor 的方式创建，这样的方式让写的同学更加明确线程池的运行的规则，避免资源耗尽的风险。例如上述前两个使用的阻塞队列是 LinkedBlockingQueue 该阻塞队列虽有界但也相当于无界，因为其长度为 Integer.MAX_VALUE 将近2亿多，可能堆积大量的请求，从而导致 OOM 。也就是说实际生产中，不使用上述的 Executors 工具类来创建线程池。



**表示层解决用户信息的语法表示**

  **会话层对数据传输进行管理** 

- **8086的通用寄存器：累加器（AX），基址寄存器（BX），计数器（CX），数据寄存器（DX）**

    **变址寄存器：SI    DI**

- 

卡特兰公式：C（2n,n）/(n+1)



**哈夫曼树，则度为0的结点个数为N，度为2的结点个数为N-1，则结点总数为2N-1。** 

1. OSI 模型中，网络层最核心的功能即路由选择和分组转发。



2. 路由器在网络层，根据IP地址寻址，可以处理TCP/IP协议， 

交换机在中继层，根据MAC地址寻址 



> 传输层是进程到进程，俗称端到端。
> 网络层是主机到主机，俗称点到点。



Java中有5种创建对象的方式，

|           使用new关键字            |  } → 调用了构造函数  |
| :--------------------------------: | :------------------: |
|    使用Class类的newInstance方法    |  } → 调用了构造函数  |
| 使用Constructor类的newInstance方法 |  } → 调用了构造函数  |
|           使用clone方法            | } → 没有调用构造函数 |
|            使用反序列化            | } → 没有调用构造函数 |

**java创建线程的三种方式：**  

1.   ***继承Thread类创建线程类***
2.   ***实现Runnable接口***
3.   ***通过Callable和Future创建线程***

（1）创建Callable接口的实现类，并实现call()方法，该***call()方法将作为线程执行体，并且有返回值***。

```java

public interface Callable
{
　　V call() throws Exception;
}
```

（2）创建Callable实现类的实例，**使用FutureTask类来包装Callable对象**，该FutureTask对象封装了该Callable对象的call()方

法的返回值。（**FutureTask是一个包装器**，它通过接受Callable来创建，它***同时实现了Future和Runnable接口***。）

（3）使用FutureTask对象作为Thread对象的target创建并启动新线程。

（4）调用FutureTask对象的get()方法来获得子线程执行结束后的返回值

```java

public class CallableThreadTest implements Callable<Integer>  

{  
    public static void main(String[] args)  
    {  
        CallableThreadTest ctt = new CallableThreadTest();  
        FutureTask<Integer> ft = new FutureTask<>(ctt);  
        for(int i = 0;i < 100;i++)  
        {  
            log.info(Thread.currentThread().getName()+" 的循环变量i的值"+i);  
            if(i==20)  
            {  
                new Thread(ft,"有返回值的线程").start();  
            }  
        }  
        try  
        {  
            log.info("子线程的返回值："+ft.get());  
        } catch (InterruptedException e)  
        {  
            e.printStackTrace();  
        } catch (ExecutionException e)  
        {  
            e.printStackTrace();  
        }  
    }  
    @Override  
    public Integer call() throws Exception  
    {  
        int i = 0;  
        for(;i<100;i++)  
        {  
            log.info(Thread.currentThread().getName()+" "+i);  
        }  
        return i;  
    }  
}  
```

**Java 线程池**

Java通过Executors提供四种线程池，分别为：

> **newCachedThreadPool**        创建一个可缓存线程池，如果线程池长度超过处理需要，可灵活回收空闲线程，若无可回收，则新建线程。
> **newFixedThreadPool**             创建一个定长线程池，可控制线程最大并发数，超出的线程会在队列中等待。
> **newScheduledThreadPool**   创建一个定长线程池，支持定时及周期性任务执行。
> **newSingleThreadExecutor**   创建一个单线程化的线程池，它只会用唯一的工作线程来执行任务，保证所有任务按照指定顺序(FIFO, LIFO, 优先级)执行。

**`ThreadLocal` 主要解决2类问题:**

1. 并发问题:使用 `ThreadLocal` 代替 `Synchronized` 来保证线程安全,同步机制采用空间换时间 -> 仅仅先提供一份变量，各个线程轮流访问，后者每个线程都持有一份变量，访问时互不影响。
2. 数据存储问题:  `ThreadLocal` 为变量在每个线程中创建了一个副本，所以每个线程可以访问自己内部的副本变量。

**原理**

`ThreadLocal` 主要分为2个部分:第一部分是它的一些成员属性,这部分主要和计算哈希值相关的。另一部分是它对外提供的几个API,这些方法可以操作它自己内部非常重要的内部类 `ThreadLocalMap` 所以说它才是 `ThreadLocal` 的底层实现。
 通过前面基本知道了怎么使用 `ThreadLocal` 了，并且知道了它可以为每个线程提供一个局部的变量副本,实现了线程之间的数据隔离,提高程序的并发性等,但是我们并不知道它是如何实现这部分的功能的。所以这部分开始读码了解底层原理,在了解原理之前,得先知道 `Thread ThreadLocal ThreadLocalMap` 之间的关系。概括一下: ThreadLocal 并不是把 Thread 作为 key  副本值作为 value的一种类似 HashMap 的结构。而是每个 `Thread` 里都有一个 `ThreadLocalMap`,`ThreadLocal` 只是操作每个线程的 ThreadLocalMap 而已。

**Java多线程状态转换**

![1683887-20200228092557797-201409676.jpg](D:\Typora\图片\1683887-20200228092557797-201409676.jpg.png)

1、新建（new）：线程对象被创建后就进入了新建状态。如：Thread thread = new Thread();

2、就绪状态（Runnable）：也被称为“可执行状态”。线程对象被创建后，其他线程调用了该对象的start()方法，从而启动该线程。如：thread.start(); 处于就绪状态的线程随时可能被CPU调度执行。

3、运行状态（Running）：线程获取CPU权限进行执行。需要注意的是，线程只能从就绪状态进入到运行状态。

4、阻塞状态（Blocked）：阻塞状态是线程因为某种原因放弃CPU使用权限，暂时停止运行。直到线程进入就绪状态，才有机会进入运行状态。阻塞的三种情况：

  1）等待阻塞：通过调用线程的wait()方法，让线程等待某工作的完成。

  2）同步阻塞：线程在获取synchronized同步锁失败（因为锁被其他线程占用），它会进入同步阻塞状态。

  3）其他阻塞：通过调用线程的sleep()或join()或发出了I/O请求时，线程会进入到阻塞状态。当sleep()状态超时、join()等待线程终止或超时、或者I/O处理完毕时，线程重新转入就绪状态。

5、死亡状态（Dead）：线程执行完了或因异常退出了run()方法，该线程结束生命周期。 

 **深拷贝和浅拷贝区别是什么？**

- 浅拷贝只是复制了对象的引用地址，两个对象指向同一个内存地址，所以修改其中任意的值，另一个值都会随之变化，这就是浅拷贝（例：assign()）
- 深拷贝是将对象及值复制过来，两个对象修改其中任意的值另一个值不会改变，这就是深拷贝（例：JSON.parse()和JSON.stringify()，但是此方法无法复制函数类型）

### 类加载的过程

**类加载机制：**虚拟机把描述类的数据从Class文件加载到内存，并对数据进行校验、转换解析和初始化，最终形成可以被虚拟机直接使用的Java类型，这就是虚拟机的类加载机制。

![1345979728_9052](D:\Typora\图片\1345979728_9052.jpg)

我们根据上面所说的类的生命周期来一点点剖析类的加载过程。

#### 加载

我们首先要明白一件事情：什么开始进行类加载过程的第一阶段：加载？Java虚拟机没有进行强制约束，交由虚拟机的具体实现自由把握。

看完上面的话，我们来看在加载阶段，虚拟机需要完成哪些事情

> - 通过一个类的全限定名来获取定义此类的二进制字节流
> - 将获取到的二进制字节流转化成一种数据结构并放进方法区
> - 在内存中生成一个代表此类的java.lang.Class对象，作为访问方法区中各种数据的接口

[[并发编程]](https://github.com/Homiss/Java-interview-questions/blob/master/%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B/Java%E7%BD%91%E7%BB%9C%E7%BC%96%E7%A8%8B%E9%9D%A2%E8%AF%95%E9%A2%98.md)





![img](https://img-blog.csdn.net/20170907003603751?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvU2lsZW5jZU9P/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

**双亲委派模型的工作过程为**：如果一个类加载器收到了类加载的请求，它首先不会自己去尝试加载这个类，而是把这个请求委派给父类加载器去完成，每一个层次的加载器都是如此，因此所有的类加载请求都会传给顶层的启动类加载器，只有当父加载器反馈自己无法完成该加载请求（该加载器的搜索范围中没有找到对应的类）时，子加载器才会尝试自己去加载。

​		使用这种模型来组织类加载器之间的关系的好处是Java类随着它的类加载器一起具备了一种带有优先级的层次关系。例如java.lang.Object类，无论哪个类加载器去加载该类，最终都是由启动类加载器进行加载，因此Object类在程序的各种类加载器环境中都是同一个类。否则的话，如果不使用该模型的话，如果用户自定义一个java.lang.Object类且存放在classpath中，那么系统中将会出现多个Object类，应用程序也会变得很混乱。如果我们自定义一个rt.jar中已有类的同名Java类，会发现JVM可以正常编译，但该类永远无法被加载运行。

### 进程与线程的基础区别：

1、**进程是资源分配的最小单位，线程是程序执行的最小单位（资源调度的最小单位）**
 2、进程有自己的独立地址空间，每启动一个进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段和数据段，这种操作非常昂贵。
 而线程是共享进程中的数据的，使用相同的地址空间，因此CPU切换一个线程的花费远比进程要小很多，同时创建一个线程的开销也比进程要小很多。
 3、线程之间的通信更方便，同一进程下的线程共享全局变量、静态变量等数据，而进程之间的通信需要以通信的方式（IPC)进行。不过如何处理好同步与互斥是编写多线程程序的难点。
 4、但是多进程程序更健壮，多线程程序只要有一个线程死掉，整个进程也死掉了，而一个进程死掉并不会对另外一个进程造成影响，因为进程有自己独立的地址空间。

### 常见的进程间通信方式

> 1. **管道（Pipe）**：管道是一种半双工的通信方式，数据只能单向流动，而且只能在具有亲缘关系进程间的通信，允许一个进程和另一个与它有共同祖先的进程之间进行通信。（半双工：数据传输指数据可以在一个信号载体的两个方向上传输，但是不能同时传输。）
> 2. **有名管道（named pipe）**： 有名管道也是半双工的通信方式，但是它允许无亲缘关系进程间的通信。命名管道在文件系统中有对应的文件名。命名管道通过命令 mkfifo 或系统调用 mkfifo 来创建。
> 3. 信号（Signal）：信号是比较复杂的通信方式，用于通知接受进程有某种事件发生。
> 4. **消息（Message）队列**：消息队列是消息的链接表。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。
> 5. 共享内存：使得多个进程可以访问同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。往往与其它通信机制，如信号量结合使用，来达到进程间的同步及互斥。
> 6. 内存映射（mapped memory）：内存映射允许任何多个进程间通信，每一个使用该机制的进程通过把一个共享的文件映射到自己的进程地址空间来实现它。
> 7. 信号量（semaphore）：信号量是一个计数器，可以用来控制多个进程对共享资源的访问。它常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段。
> 8. 套接口（Socket）：更为一般的进程间通信机制，与其他通信机制不同的是，它可用于不同及其间的进程通信。可用于不同机器之间的进程间通信。
>
> 

### **集合总结**

Java1.5并发包（java.util.concurrent）**包含线程安全集合类，允许在迭代时修改集合**。

- 迭代器被设计为fail-fast的，会抛出ConcurrentModificationException。

- 一部分类为：

- - CopyOnWriteArrayList
  - ConcurrentHashMap
  - CopyOnWriteArraySet

1. **hashmap和hashtable的区别**

 （1）继承的父类不同

   Hashtable继承自Dictionary类，而HashMap继承自AbstractMap类。但二者都实现了Map接口。

（2）线程安全不同

HashTable是线程安全的，HashTable内部的方法基本都使用了synchronized关键字修饰

如果你要保证线程安全，推荐使用ConcurrentHashMap

（3）底层数据结构

-  JDK1.8 以后的 HashMap 在解决哈希冲突时有了较大的变化，当链表长度大于阈值（默认为8）时，将链表转化为红黑树，以减少搜索时间；
- Hashtable 没有这样的机制。

（4）初始容量和每次扩充容量的大小不同

- HashMap创建的时候如果不指定容量大小，初始容量大小为16，之后每次扩充，容量变为原来的2倍；
- HashTable创建的时候如果不指定容量大小，初始容量大小为11，之后每次扩充，容量会变为2n + 1；
- HashMap创建的时候给定初始容量大小，HashMap 会将其扩充为2的幂次方大小（HashMap 中的`tableSizeFor()`方法保证，下面给出了源代码）。也就是说 HashMap 总是使用2的幂作为哈希表的大小,后面会介绍到为什么是2的幂次方。

(5) 对于Null Key和Null Value的支持

- HashMap中，null可以作为key，但是这样的key只能有一个；可以有一个或者多个键对应的value为null;
- HashTable中不支持key为null，如果put使用null，那么就会抛出NullPointerException异常；

### **数据库范式**

​		**第一范式**就是属性不可分割，每个字段都应该是不可再拆分的。比如一个字段是姓名（NAME），在国内的话通常理解都是姓名是一个不可再拆分的单位，这时候就符合第一范式；但是在国外的话还要分为FIRST NAME和LAST NAME，这时候姓名这个字段就是还可以拆分为更小的单位的字段，就不符合第一范式了。

​		**第二范式**就是要求表中要有主键，表中其他其他字段都依赖于主键，因此第二范式只要记住主键约束就好了。比如说有一个表是学生表，学生表中有一个值唯一的字段学号，那么学生表中的其他所有字段都可以根据这个学号字段去获取，依赖主键的意思也就是相关的意思，因为学号的值是唯一的，因此就不会造成存储的信息对不上的问题，即学生001的姓名不会存到学生002那里去。

​		**第三范式**就是要求表中不能有其他表中存在的、存储相同信息的字段，通常实现是在通过外键去建立关联，因此第三范式只要记住外键约束就好了。比如说有一个表是学生表，学生表中有学号，姓名等字段，那如果要把他的系编号，系主任，系主任也存到这个学生表中，那就会造成数据大量的冗余，一是这些信息在系信息表中已存在，二是系中有1000个学生的话这些信息就要存1000遍。因此第三范式的做法是在学生表中增加一个系编号的字段（外键），与系信息表做关联。

### **TCP、UDP**

#### 	1. **TCP**

​	位于传输层， 提供可靠的字节流服务。所谓的字节流服务（Byte Stream Service） 是指， 为了方便传输， 将大块数据分割成以报文段（segment） 为单位的数据包进行管理。 而可靠的传输服务是指， 能够把数据准确可靠地传给对方。 即TCP 协议为了更容易传送大数据才把数据分割， 而且 TCP 协议能够确认数据最终是否送达到对方。所以，TCP连接相当于两根管道（一个用于服务器到客户端，一个用于客户端到服务器），管道里面数据传输是通过字节码传输，传输是有序的，每个字节都是一个一个来传输。 

**(1)、三次握手：**握手过程中使用了 TCP 的标志（flag） —— SYN（synchronize） 和ACK（acknowledgement）

- 第一次握手：建立连接时，客户端A发送SYN包（SYN=j）到服务器B，并进入SYN_SEND状态，等待服务器B确认。
- 第二次握手：服务器B收到SYN包，必须确认客户A的SYN（ACK=j+1），同时自己也发送一个SYN包（SYN=k），即SYN+ACK包，此时服务器B进入SYN_RECV状态。
- 第三次握手：客户端A收到服务器B的SYN＋ACK包，向服务器B发送确认包ACK（ACK=k+1），此包发送完毕，完成三次握手。



![img](https://img-blog.csdnimg.cn/20181114111936855.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3N0cml2ZWI=,size_16,color_FFFFFF,t_70)



 **（2）、四次挥手：**由于TCP连接是全双工的，因此每个方向都必须单独进行关闭。这个原则是当一方完成它的数据发送任务后就能发送一个FIN来终止这个方向的连接。收到一个 FIN只意味着这一方向上没有数据流动，一个TCP连接在收到一个FIN后仍能发送数据。先进行关闭的一方将执行主动关闭，而另一方被动关闭。

- 客户端A发送一个FIN，用来关闭客户A到服务器B的数据传送。
- 服务器B收到这个FIN，它发回一个ACK，确认序号为收到的序号加1。
- 服务器B关闭与客户端A的连接，发送一个FIN给客户端A。
- 客户端A发回ACK报文确认，并将确认序号设置为收到序号加1。

**三次握手和四次挥手：**在TCP连接中，服务器端的SYN和ACK向客户端发送是一次性发送的，而在断开连接的过程中， B端向A
 端发送的ACK和FIN是分两次发送的。因为在B端接收到A端的FIN后， B端可能还有数据要传输，所以先发送ACK，等B端处理完自己的事情后就可以发送FIN断开连接了。

2. #### **UDP**

无连接协议，也称透明协议，也位于传输层。

两者区别：

1） TCP提供面向连接的传输，通信前要先建立连接（三次握手机制）； UDP提供无连接的传输，通信前不需要建立连接。
 2） TCP提供可靠的传输（有序，无差错，不丢失，不重复）； UDP提供不可靠的传输。
 3） TCP面向字节流的传输，因此它能将信息分割成组，并在接收端将其重组； UDP是面向数据报的传输，没有分组开销。
 4） TCP提供拥塞控制和流量控制机制； UDP不提供拥塞控制和流量控制机制。





### 泛型

“泛型” 意味着编写的代码可以被不同类型的对象所重用。

泛型是在JDK1.5之后出现的。

泛型的本质是参数化类型，也就是说所操作的数据类型被指定为一个参数。

可以看到，使用 Object 来实现通用、不同类型的处理，有这么两个缺点：

1. 每次使用时都需要强制转换成想要的类型
2. 在编译时编译器并不知道类型转换是否正常，运行时才知道，不安全

### **JVM总结**

![img](https://img-blog.csdnimg.cn/20181226105629124.jpg?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3FxXzMyNzU1NzU3,size_16,color_FFFFFF,t_70)

1. **程序计数器**

   程序计数器是当前线程所执行的行号指示器。通过改变计数器的值来确定下一条指令，比如循环，分支，跳转，异常处理，线程恢复等都依赖计数器来完成。

2. **虚拟机栈** 

   ​        虚拟机栈也就是我们所说的栈内存，是java方法执行的内存模型。每个方法在执行的时候都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、和方法返回地址等信息。

   ​        局部变量表存储的是基本数据类型、returnAdress类型和对象引用。局部变量表的大小在编译期间完成分配，因此程序执行期间局部变量表的大小不会改变。

   ​        操作数栈主要用来存储运算结果及运算的操作数。在数据结构中，栈最典型的一个应用就是用来对表达式求值。程序中的所有计算过程都是借助操作数栈完成的。

   ​		每个栈帧都包含一个指向运行时常量池中该栈帧所属方法的引用，持有这个引用是为了支持方法调用中的动态链接就是将常量池中的符号引用在运行期间转化为直接引用。

3. **本地方法栈**

   本地方法栈和虚拟机栈类似，只不过本地方法栈为虚拟机使用本地方法（native）服务。

4. **堆** 

   java堆是所有线程共享的一块内存，在虚拟机启动是创建，几乎所有的对象实例都在这里创建，因此该区域经常发生垃圾回收。从内存回收的角度看，由于现在收集器基本都是采用分代收集算法，所以java堆中还可以细分为：新生代和老年代；新生代又分为Eden空间、From Survivor空间、To Survivor空间三部分。

5. **方法区**

​        方法区和java堆一样，是各个线程共享的内存区域，不需要连续的内存，并且可以动态扩展，动态扩展失败一样会抛出OutOfMemoryError异常。方法区用于存放已被虚拟机加载的类信息、常量、静态变量、即时编译器编译后的代码等数据。虽然Java虚拟机规范把方法区描述为堆的一个逻辑部分，但是为了与java堆区分开，方法区又叫非堆（Non-Heap）,很多人更愿意把方法区称为“永久代”。从jdk1.7已经开始准备“去永久代”的规划，jdk1.7的HotSpot中，已经把原来放在方法区中的静态变量，字符串常量池等移到堆内存中。在jdk1.8中，永久代已经不存在，存储的类信息、即时编译器编译后的代码等已经移动到元空间（MetaSpace）中，元空间并没有处于堆内存上，而是直接占用本地内存（NativeMemory）。

​		运行时常量池属于方法区的一部分，常量池中存放2类常量：字面量和符号引用。字面量比较接近java语言层面的常量概念，如文本字符串，被声明为final的常量值等。而符号引用则属于编译原理方面的概念，包括3类常量：类和接口的全限定名、字段的名称和描述符，方法的名称和描述符。

### **Linux总结**





### **MyBatis总结**

1. mybatis一级缓存和二级缓存

**mybatis的的一级缓存是SqlSession级别的缓存，一级缓存缓存的是对象，当SqlSession提交、关闭以及其他的更新数据库的操作发生后，一级缓存就会清空。二级缓存是SqlSessionFactory级别的缓存，同一个SqlSessionFactory产生的SqlSession都共享一个二级缓存，二级缓存中存储的是数据，当命中二级缓存时，通过存储的数据构造对象返回。查询数据的时候，查询的流程是二级缓存>一级缓存>数据库**







### **Spring总结**

容器启动的过程可以分为2大步

   1:获取、解析、注册配置信息,将配置的文件信息转换Map<name,beanDefinition>

   2:根据上述的Map<name,beanDefinition>去实例化bean，并完成以来注入



**1. Spring springmvc 的启动流程**

Spring的启动是建筑在servlet容器之上的，所有web工程的初始位置就是web.xml,它配置了servlet的上下文（context）和监听器（Listener）

```java

<context-param>
        <param-name>contextConfigLocation</param-name>
        <param-value>/WEB-INF/spring/application_context.xml</param-value>
</context-param>
<listener>
        <listener-class>
            org.springframework.web.context.ContextLoaderListener
        </listener-class>
 </listener>

```

spring的启动其实就是IOC容器的启动过程，通过上述的第一段配置`<context-param>`是初始化上下文，然后通过后一段的的<listener>来加载配置文件，其中调用的spring包中的`ContextLoaderListener`这个上下文监听器，`ContextLoaderListener`是一个实现了`ServletContextListener`接口的监听器，他的父类是 `ContextLoader`，在启动项目时会触发`contextInitialized`上下文初始化方法。



在 Spring 中，构成应用程序**主干**并由**Spring IoC容器**管理的**对象**称为**bean**。bean是一个由Spring IoC容器实例化、组装和管理的对象。

**1、Spring是什么？有什么特点？**

（1）Spring是**一个轻量级Java开发框架**，最早有**Rod Johnson**创建。

（2）Spring设计目标：Spring为开发者提供一个一站式轻量级应用开发平台；

（3）Spring设计理念：在JavaEE开发中，支持POJO和JavaBean开发方式，使应用面向接口开发，充分支持OO（面向对象）设计方法；Spring通过IoC容器实现对象耦合关系的管理，并实现依赖反转，将对象之间的依赖关系交给IoC容器，实现解耦；

（4）Spring框架的核心：IoC容器和AOP模块。通过IoC容器管理POJO对象以及他们之间的耦合关系；通过AOP以动态非侵入的方式增强服务。

**2、详细讲解一下核心容器（spring context应用上下文) 模块**

这是基本的Spring模块，提供spring 框架的基础功能，BeanFactory 是 任何以spring为基础的应用的核心。Spring 框架建立在此模块之上，它使Spring成为一个容器。

Bean 工厂是工厂模式的一个实现，提供了控制反转功能，用来把应用的配置和依赖从真正的应用代码中分离。最常用的就是org.springframework.beans.factory.xml.XmlBeanFactory ，它根据XML文件中的定义加载beans。该容器从XML 文件读取配置元数据并用它去创建一个完全配置的系统或应用。

**二、面向切面编程(AOP)**

**1、什么是AOP**

AOP(Aspect-Oriented Programming)，一般称为面向切面编程，作为面向对象的一种补充，用于将那些与业务无关，但却对多个对象产生影响的公共行为和逻辑，抽取并封装为一个可重用的模块，这个模块被命名为“切面”（Aspect），减少系统中的重复代码，降低了模块间的耦合度，同时提高了系统的可维护性。可用于权限认证、日志、事务处理等。

**2、Spring AOP and AspectJ AOP 有什么区别？AOP 有哪些实现方式？**

AOP实现的关键在于 代理模式，AOP代理主要分为静态代理和动态代理。静态代理的代表为AspectJ；动态代理则以Spring AOP为代表。

（1）AspectJ是静态代理的增强，所谓静态代理，就是AOP框架会在编译阶段生成AOP代理类，因此也称为编译时增强，他会在编译阶段将AspectJ(切面)织入到Java字节码中，运行的时候就是增强之后的AOP对象。

（2）Spring AOP使用的动态代理，所谓的动态代理就是说AOP框架不会去修改字节码，而是每次运行时在内存中临时为方法生成一个AOP对象，这个AOP对象包含了目标对象的全部方法，并且在特定的切点做了增强处理，并回调原对象的方法。

**3、JDK动态代理和CGLIB动态代理的区别**

Spring AOP中的动态代理主要有两种方式，JDK动态代理和CGLIB动态代理：

（1）JDK动态代理只提供接口的代理，不支持类的代理。核心InvocationHandler接口和Proxy类，InvocationHandler 通过invoke()方法反射来调用目标类中的代码，动态地将横切逻辑和业务编织在一起；接着，Proxy利用 InvocationHandler动态创建一个符合某一接口的的实例, 生成目标类的代理对象。

（2）如果代理类没有实现 InvocationHandler 接口，那么Spring AOP会选择使用CGLIB来动态代理目标类。CGLIB（Code Generation Library），是一个代码生成的类库，可以在运行时动态的生成指定类的一个子类对象，并覆盖其中特定方法并添加增强代码，从而实现AOP。CGLIB是通过继承的方式做的动态代理，因此如果某个类被标记为final，那么它是无法使用CGLIB做动态代理的。

静态代理与动态代理区别在于生成AOP代理对象的时机不同，相对来说AspectJ的静态代理方式具有更好的性能，但是AspectJ需要特定的编译器进行处理，而Spring AOP则无需特定的编译器处理。

4. **Spring生命周期**

![img](https://user-gold-cdn.xitu.io/2019/4/5/169ee0ffc7699bf7?w=790&h=228&f=png&s=20462)



![preview](https://pic1.zhimg.com/754a34e03cfaa40008de8e2b9c1b815c_r.jpg?source=1940ef5c)

四个方面

1. 实例化 Instantiation
2. 属性赋值 Populate
3. 初始化 Initialization
4. 销毁 Destruction



实例化 -> 属性赋值 -> 初始化 -> 销毁

**五、@Component 和 @Bean 的区别是什么？**

1. 作用对象不同: @Component 注解作用于类，而@Bean注解作用于方法。
2. @Component通常是通过类路径扫描来自动侦测以及自动装配到Spring容器中（我们可以使用 @ComponentScan 注解定义要扫描的路径从中找出标识了需要装配的类自动装配到 Spring 的 bean 容器中）。@Bean 注解通常是我们在标有该注解的方法中定义产生这个 bean,@Bean告诉了Spring这是某个类的示例，当我需要用它的时候还给我。
3. @Bean 注解比 Component 注解的自定义性更强，而且很多地方我们只能通过 @Bean 注解来注册bean。比如当我们引用第三方库中的类需要装配到 Spring容器时，则只能通过 @Bean来实现。



**SpringMVC**

SpringMVC运行原理：

![SpringMVC](D:\Typora\图片\SpringMVC.jpg)

**流程说明（重要）**：

1. 客户端（浏览器）发送请求，直接请求到 DispatcherServlet。
2. DispatcherServlet 根据请求信息调用 HandlerMapping，解析请求对应的 Handler。
3. 解析到对应的 Handler（也就是我们平常说的 Controller 控制器）后，开始由 HandlerAdapter 适配器处理。
4. HandlerAdapter 会根据 Handler来调用真正的处理器开处理请求，并处理相应的业务逻辑。
5. 处理器处理完业务后，会返回一个 ModelAndView 对象，Model 是返回的数据对象，View 是个逻辑上的 View。
6. ViewResolver 会根据逻辑 View 查找实际的 View。
7. DispaterServlet 把返回的 Model 传给 View（视图渲染）。
8. 把 View 返回给请求者（浏览器）



### **Redis总结**

**1. redis 是什么？都有哪些使用场景？**

Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。

Redis 使用场景：

- 数据高并发的读写
- 海量数据的读写
- 对扩展性要求高的数据

**2. redis 有哪些功能？**

- 数据缓存功能
- 分布式锁的功能
- 支持数据持久化
- 支持事务
- 支持消息队列

3. **redis 和 memecache 有什么区别？**

- memcached所有的值均是简单的字符串，redis作为其替代者，支持更为丰富的数据类型
- redis的速度比memcached快很多
- redis可以持久化其数据

**4. redis 为什么是单线程的？**

因为 cpu 不是 Redis 的瓶颈，Redis 的瓶颈最有可能是机器内存或者网络带宽。既然单线程容易实现，而且 cpu 又不会成为瓶颈，那就顺理成章地采用单线程的方案了。



关于 Redis 的性能，官方网站也有，普通笔记本轻松处理每秒几十万的请求。



而且单线程并不代表就慢 nginx 和 nodejs 也都是高性能单线程的代表。

**5. 什么是缓存穿透？怎么解决？**

缓存穿透：指查询一个一定不存在的数据，由于缓存是不命中时需要从数据库查询，查不到数据则不写入缓存，这将导致这个不存在的数据每次请求都要到数据库去查询，造成缓存穿透。



解决方案：最简单粗暴的方法如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们就把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。

**6 redis 支持的数据类型有哪些？**

string、list、hash、set、zset。

**7. redis 支持的 java 客户端都有哪些？**

Redisson、Jedis、lettuce等等，官方推荐使用Redisson。

**8. jedis 和 redisson 有哪些区别？**

Jedis是Redis的Java实现的客户端，其API提供了比较全面的Redis命令的支持。

Redisson实现了分布式和可扩展的Java数据结构，和Jedis相比，功能较为简单，不支持字符串操作，不支持排序、事务、管道、分区等Redis特性。Redisson的宗旨是促进使用者对Redis的关注分离，从而让使用者能够将精力更集中地放在处理业务逻辑上。

**9. 怎么保证缓存和数据库数据的一致性？**

- 合理设置缓存的过期时间。
- 新增、更改、删除数据库操作时同步更新 Redis，可以使用事物机制来保证数据的一致性。

**10. redis 持久化有几种方式？**

Redis 的持久化有两种方式，或者说有两种策略：

- RDB（Redis Database）：指定的时间间隔能对你的数据进行快照存储。
- AOF（Append Only File）：每一个收到的写命令都通过write函数追加到文件中。

**11. redis 怎么实现分布式锁？**

Redis 分布式锁其实就是在系统里面占一个“坑”，其他程序也要占“坑”的时候，占用成功了就可以继续执行，失败了就只能放弃或稍后重试。



占坑一般使用 setnx(set if not exists)指令，只允许被一个程序占有，使用完调用 del 释放锁。

**12. redis 分布式锁有什么缺陷？**

Redis 分布式锁不能解决超时的问题，分布式锁有一个超时时间，程序的执行如果超出了锁的超时时间就会出现问题。

**13. redis 如何做内存优化？**

尽可能使用散列表（hashes），散列表（是说散列表里面存储的数少）使用的内存非常小，所以你应该尽可能的将你的数据模型抽象到一个散列表里面。



比如你的web系统中有一个用户对象，不要为这个用户的名称，姓氏，邮箱，密码设置单独的key,而是应该把这个用户的所有信息存储到一张散列表里面。

**14. redis 淘汰策略有哪些？**

- volatile-lru：从已设置过期时间的数据集（server. db[i]. expires）中挑选最近最少使用的数据淘汰。
- volatile-ttl：从已设置过期时间的数据集（server. db[i]. expires）中挑选将要过期的数据淘汰。
- volatile-random：从已设置过期时间的数据集（server. db[i]. expires）中任意选择数据淘汰。
- allkeys-lru：从数据集（server. db[i]. dict）中挑选最近最少使用的数据淘汰。
- allkeys-random：从数据集（server. db[i]. dict）中任意选择数据淘汰。
- no-enviction（驱逐）：禁止驱逐数据。

**15. redis 常见的性能问题有哪些？该如何解决？**

- 主服务器写内存快照，会阻塞主线程的工作，当快照比较大时对性能影响是非常大的，会间断性暂停服务，所以主服务器最好不要写内存快照。
- Redis 主从复制的性能问题，为了主从复制的速度和连接的稳定性，主从库最好在同一个局域网内。